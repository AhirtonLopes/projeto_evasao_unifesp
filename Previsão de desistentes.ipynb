{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%writefile requirements.txt\n",
    "\n",
    "####### requirements for project\n",
    "####### python 3.5\n",
    "\n",
    "####### lista extensa do environment, depois filtro para os que foram utilizados realmente\n",
    "#ipython==5.1.0\n",
    "#jupyter==1.0.0\n",
    "#matplotlib==1.5.3\n",
    "#notebook==4.2.3\n",
    "#pandas==0.18.1\n",
    "#xlrd==1.0.0\n",
    "#scikit-learn==0.18.1\n",
    "\n",
    "####### the following must be installed separately\n",
    "# \n",
    "# \n",
    "\n",
    "####### para instalar utilize os seguintes comandos no linux (Ubuntu e similares):\n",
    "# sudo apt-get install python-pip python-dev\n",
    "# sudo pip install virtualenv virtualenvwrapper\n",
    "# echo \"export WORKON_HOME=~/envs\" >> ~/.bashrc\n",
    "# echo \"source /usr/local/bin/virtualenvwrapper.sh\" >> ~/.bashrc\n",
    "# echo \"export PIP_REQUIRE_VIRTUALENV=true\" >> ~/.bashrc\n",
    "# source ~/.bashrc\n",
    "# mkvirtualenv <env_name> -p /usr/bin/python3\n",
    "####### substitua <env_name> pelo nome de preferência para seu ambiente virtual\n",
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evasão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformacao_colunas = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../bd/BANCO_FINAL.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dca3c6846a51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../bd/BANCO_FINAL.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ricardo/envs/py3/local/lib/python3.5/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheetname, header, skiprows, skip_footer, index_col, names, parse_cols, parse_dates, date_parser, na_values, thousands, convert_float, has_index_names, converters, engine, squeeze, **kwds)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \"\"\"\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     return io._parse_excel(\n",
      "\u001b[0;32m/home/ricardo/envs/py3/local/lib/python3.5/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, **kwds)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[0;32m/home/ricardo/envs/py3/local/lib/python3.5/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../bd/BANCO_FINAL.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('../bd/BANCO_FINAL.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Calculate number of students\n",
    "n_students = data.shape[0]\n",
    "\n",
    "# TODO: Calculate number of features\n",
    "n_features = len(data.columns[:-2])\n",
    "\n",
    "# TODO: Calculate passing students\n",
    "n_curso = data[data.DESISTENTE == 'SIM'].shape[0]\n",
    "\n",
    "# TODO: Calculate failing students\n",
    "n_desistentes = data[data.DESISTENTE == 'NÃO'].shape[0]\n",
    "\n",
    "# TODO: Calculate graduation rate\n",
    "grad_rate = 1 - n_desistentes/n_students\n",
    "\n",
    "# Print the results\n",
    "print (\"Número total de estudantes: {}\".format(n_students))\n",
    "print (\"Número de características: {}\".format(n_features))\n",
    "print (\"Número de estudantes em curso: {}\".format(n_curso))\n",
    "print (\"Número de estudantes desistentes: {}\".format(n_desistentes))\n",
    "print (\"Taxa de desistentes: {:.2f}%\".format(grad_rate*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(list(data.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract feature columns\n",
    "feature_cols = ['CAMPUS', 'ANO', 'Q1', 'Q2', 'Q3', \n",
    "                'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9',\n",
    "                'Q10', 'Q11', 'Q12', 'Q13', 'Q14',\n",
    "                'Q15', 'Q16', 'Q17', 'Q18', 'Q19',\n",
    "                'CR', 'renda sm',\n",
    "                'Pessoas que vivem com essa renda', 'renda per']\n",
    "\n",
    "# Extract target column 'passed'\n",
    "target_col = ['DESISTENTE']\n",
    "\n",
    "# Show the list of columns\n",
    "print (\"Feature columns:\\n{}\".format(feature_cols))\n",
    "print (\"\\nTarget column: {}\".format(target_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Início de tratamentos para ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformar_em_numeros = False\n",
    "\n",
    "if transformar_em_numeros:\n",
    "    from sklearn import preprocessing\n",
    "    \n",
    "    ## Vamos tornar os atributos em números \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    dicionario = []\n",
    "    features_ = feature_cols.copy()\n",
    "    ## removendo os atributos que não precisam ser transformados em números\n",
    "    features_.remove('renda sm')\n",
    "    features_.remove('Pessoas que vivem com essa renda')\n",
    "    features_.remove('renda per')\n",
    "    features_.remove('ANO')\n",
    "    features_.remove('CR')\n",
    "    features_.remove('Q9')\n",
    "    features_.append(target_col[0])\n",
    "    print(features_)\n",
    "    \n",
    "    for i in features_:\n",
    "        dicionario.extend(list(data[i]))\n",
    "    \n",
    "    le.fit(dicionario)\n",
    "    for i in features_:\n",
    "        data[i] = list(le.transform(data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate the data into feature data and target data (X_all and y_all, respectively)\n",
    "X_all = data[feature_cols]\n",
    "y_all = data[target_col]\n",
    "\n",
    "## Show the feature information by printing the first five rows\n",
    "#print (\"Feature values:\")\n",
    "#print (X_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tranformacao_1_para_n = True\n",
    "\n",
    "if tranformacao_1_para_n:\n",
    "    def preprocess_features(X):\n",
    "        ''' Preprocesses the student data and converts non-numeric binary variables into\n",
    "            binary (0/1) variables. Converts categorical variables into dummy variables. '''\n",
    "\n",
    "        # Initialize new output DataFrame\n",
    "        output = pd.DataFrame(index = X.index)\n",
    "\n",
    "        # Investigate each feature column for the data\n",
    "        for col, col_data in X.iteritems():\n",
    "\n",
    "            # If data type is non-numeric, replace all yes/no values with 1/0\n",
    "            if col_data.dtype == object:\n",
    "                col_data = col_data.replace(['SIM', 'NÃO'], [1, 0])\n",
    "\n",
    "            # If data type is categorical, convert to dummy variables\n",
    "            if col_data.dtype == object:\n",
    "                # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "                col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "\n",
    "            # Collect the revised columns\n",
    "            output = output.join(col_data)\n",
    "\n",
    "        return output\n",
    "\n",
    "    X_all = preprocess_features(X_all)\n",
    "    #y_all = preprocess_features(y_all)\n",
    "#print (\"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: Set the number of training points\n",
    "num_train = 5010\n",
    "\n",
    "# Set the number of testing points\n",
    "num_test = X_all.shape[0] - num_train\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all,\n",
    "                                                    test_size=num_test, random_state=42)\n",
    "\n",
    "# Show the results of the split\n",
    "print (\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print (\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando os modelos e parâmetros para otimização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo os tamanhos da base de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf_A_params = \"\"\n",
    "\n",
    "clf_B_params = { 'criterion' : ('gini', 'entropy'),\n",
    "           'min_samples_split' : (2, 10, 40),\n",
    "           'min_samples_leaf' : (1, 3, 7, 40)}\n",
    "\n",
    "clf_C_params = {'n_estimators' : (10, 2, 3, 5, 7),\n",
    "           'criterion' : ('gini', 'entropy'),\n",
    "           'min_samples_split' : (2, 10, 40),\n",
    "           'min_samples_leaf' : (1, 5, 10, 40)}\n",
    "\n",
    "clf_D_params = { 'kernel' : ('linear', 'poly', 'rbf')} \n",
    "\n",
    "models = {\"GaussianNB\": [GaussianNB(), clf_A_params],\n",
    "          \"DecisionTreeClassifier\": [tree.DecisionTreeClassifier(random_state=42), clf_B_params],\n",
    "          \"Randomized Forest\": [RandomForestClassifier(random_state=42), clf_C_params],\n",
    "          \"SVM classifier\": [svm.SVC(random_state=42), clf_D_params]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "index_1670 = random.sample(range(0, 5009), 1670)\n",
    "index_3340 = random.sample(range(0, 5009), 3340)\n",
    "index_5010 = range(5010)\n",
    "\n",
    "indexes = [index_1670, index_3340, index_5010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinar, predizer e avaliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from render import train_predict\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model, params = model\n",
    "    print(\"\\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\\n\")\n",
    "    print(\"Testing Model {}\\n\".format(model_name))\n",
    "    for size in indexes:\n",
    "        X_train_i = X_train.iloc[size]\n",
    "        y_train_i = y_train.iloc[size]\n",
    "        train_predict(model, X_train_i, y_train_i, X_test, y_test, params)\n",
    "        print(\"---------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabela de resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tabela comparativa resultados](Tabela comparativa resultados.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (10, 4)\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (brier_score_loss, precision_score, recall_score, f1_score)\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "\n",
    "# Create classifiers\n",
    "svc = svm.SVC(random_state=42)\n",
    "dt = tree.DecisionTreeClassifier(random_state=42)\n",
    "gnb = GaussianNB()\n",
    "rf = RandomForestClassifier()\n",
    "classificadores = [(gnb, 'GNB'),\n",
    "                      (dt, 'DT'),\n",
    "                      (rf, \"RF\"),\n",
    "                      (svc, 'SVM')]\n",
    "\n",
    "from render import plot_calibration_curve\n",
    "plot_calibration_curve( classificadores, X_train, y_train,X_test, y_test, pos_label=\"SIM\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
